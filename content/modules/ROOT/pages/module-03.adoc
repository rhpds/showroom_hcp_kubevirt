= Creating a Hosted Cluster on OpenShift Virtualization

You can use the hosted control plane command line interface, `hcp`, to create an *OpenShift Container Platform hosted cluster*. The hosted cluster is automatically imported as a managed cluster.

== Size guidance

See the following highly available hosted control plane requirements, which were tested with OpenShift Container Platform version 4.12.9 and later:

* 78 pods
* Three 8 GiB PVs for etcd
* Minimum vCPU: approximately 5.5 cores
* Minimum memory: approximately 19 GiB

More information: https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.9/html/clusters/cluster_mce_overview#hosted-sizing-guidance

== Prerequisites

. Connect to the bastion host of your environment
+
[source,bash,role=execute]
----
sudo ssh root@192.168.123.100
----


. Login to the OpenShift Cluster (your hosting cluster)
+
[source,bash,role=execute,subs="attributes"]
----
oc login {ocp_api} --username={ocp_username} --password={ocp_password} --insecure-skip-tls-verify=true
----

. Allow wildcard routes for your Ingress Controllers
+
[source,bash,role=execute,subs="attributes"]
----
oc patch ingresscontroller -n openshift-ingress-operator default --type=json -p '[{ "op": "add", "path": "/spec/routeAdmission", "value": {wildcardPolicy: "WildcardsAllowed"}}]'
----

== Install hcp CLI

. When Red Hat Advanced Cluster Manager for Kubernes is installed on a hosting cluster it provides a convenient download location for the `hcp` command line tool. Download the cli from your cluster:
+
[source,bash,role=execute,subs="attributes"]
----
curl -O https://hcp-cli-download-multicluster-engine.apps.{guid}.dynamic.redhatworkshops.io/linux/amd64/hcp.tar.gz
----

. Extract the client
+
[source,bash,role=execute]
----
tar xvfz hcp.tar.gz -C /usr/local/bin/
----

. Confirm that the command `hcp` is available 
+
[source,bash,role=execute]
----
hcp --version
----
+
.Sample Output
+
[%nowrap]
----
hcp version openshift/hypershift: e87182ca75da37c74b371aa0f17aeaa41437561a. Latest supported OCP: 4.14.0
----

[#create]
== Create Hosted Cluster

Some considerations:

* Run the hub cluster and workers on the same platform for hosted control planes.
* Each hosted cluster must have a unique name in order for multicluster engine operator to manage it.
* A hosted cluster cannot be created in the namespace of a multicluster engine operator managed cluster.

. Create a new hosted cluster named _cluster1_ using the command `hcp`:
+
[source,bash,role=execute]
----
hcp create cluster kubevirt \
--name cluster1 \
--release-image quay.io/openshift-release-dev/ocp-release:4.14.5-x86_64 \
--node-pool-replicas 2 \
--pull-secret ~/pull-secret.json \
--memory 6Gi \
--cores 2
----
+
.Sample Output
+
[%nowrap]
----
2023-12-02T21:49:55Z    INFO    Applied Kube resource   {"kind": "Namespace", "namespace": "", "name": "clusters"}
2023-12-02T21:49:55Z    INFO    Applied Kube resource   {"kind": "Secret", "namespace": "clusters", "name": "cluster1-pull-secret"}
2023-12-02T21:49:55Z    INFO    Applied Kube resource   {"kind": "", "namespace": "clusters", "name": "cluster1"}
2023-12-02T21:49:55Z    INFO    Applied Kube resource   {"kind": "Secret", "namespace": "clusters", "name": "cluster1-etcd-encryption-key"}
2023-12-02T21:49:55Z    INFO    Applied Kube resource   {"kind": "NodePool", "namespace": "clusters", "name": "cluster1"}
----
+
[NOTE]
The parameter `--release-image` flag to set up the hosted cluster with a specific OpenShift Container Platform release.
+
A default node pool is created for the cluster with two virtual machine worker replicas according to the `--node-pool-replicas` flag.

. Verify the host control plane are being created inside of the new namespace created (`clusters-cluster1`)
+
[source,bash,role=execute]
----
oc get pod -n clusters-cluster1
----
+
.Sample Output
+
[%nowrap]
----
NAME                                      READY   STATUS    RESTARTS   AGE
capi-provider-554c58b965-6cx78            1/1     Running   0          4m23s
cluster-api-5f5b78d889-2tnqm              1/1     Running   0          4m24s
control-plane-operator-67b7d4556b-4b4mq   1/1     Running   0          4m23s
----

. Check the status of the host clusters, querying the _Custom Resource_ named `HostedCluster`. 
+
[source,bash,role=execute]
----
oc get --namespace clusters hostedclusters
----
+
.Sample Output
+
[%nowrap]
----
NAME       VERSION   KUBECONFIG                  PROGRESS   AVAILABLE   PROGRESSING   MESSAGE
cluster1             cluster1-admin-kubeconfig   Partial    False       False         Waiting for Kube APIServer deployment to become available
----
+
[IMPORTANT]
It takes around 15 minutes until the cluster switches from Partial to Completed. You do not have to wait for the cluster to be fully deployed at this point and you may continue with the lab.

. Go back to the ACM Console (`All Clusters` in the top menu)
. Notice that the `cluster1` will appear automatically. If you don't see it yet, wait until it appears.
+
image::_images/Install/01_ACM_Review.png[]

. Click on `cluster1` and check the progress
+
image::_images/Install/02_ACM_Progress.png[]

. Review the information and scroll down and wait until the status is `Ready`

. In the middle of the screen, press `Control plane pods`
+
image::_images/Install/02_ACM_CP_pods.png[]

. Expect to see a big list of pods, as shown in the following image:
+
image::_images/Install/02_ACM_CP_pods_list.png[]

The _Hosted Control Plane_ and _Data Plane_ use the _Konnectivity_ service to establish a tunnel for communications from the control plane to the data plane. This connection works as follows:

The _Konnectivity_ agent in the compute nodes, connects with the _Konnectivity_ server running as part of the _Hosted Control Plane_.

The Kubernetes API Server uses this tunnel to communicate with the kubelet running on each compute node.

The compute nodes reach the Hosted Cluster API via an exposed service. Depending on the infrastructure where the _Hosted Control Plane_ runs this service can be exposed via a load balancer, a node port, etc.

The _Konnectivity_ server is used by the _Hosted Control Plane_ to consume services deployed in the hosted cluster namespace such as OLM, OpenShift Aggregated API and OAuth.

image::_images/Review/hcp-dp-connection.png[]

== Review creation

. While the installation continues, check OpenShift Virtualization
.. Switch back to your `local-cluster`
.. In the left menu navigate to *Virtualization* -> *Virtual Machines*
.. Select project `clusters-cluster1`
+
image::_images/Install/03_OCPV_VMs.png[]
+
CoreOS disks are imported automatically and the VMs starts. They will act as a workers for the hosted control planes cluster.

. In the left menu navigate to *Networking* -> *Services*:
+
image::_images/Install/04_OCPV_Services.png[]
+
Notice the required services for OpenShift are created inside the namespace for each cluster that has been created.

. Navigate to *Networking* -> *Routes*:
+
image::_images/Install/05_OCPV_Routes.png[]
+
The routes to access the hosted cluster from the internet are listed.

. Navigate to *Storage* -> *PersistentVolumeClaims*
+
image::_images/Install/06_OCPV_PVCs.png[]
+
Notice that the *etcd* disks for the control plane are created. These disks are used for the control planes pods. It is recommended to use a low-latency and fast I/O disks for etcd to avoid issues.

== Review creation

. Go back to *ACM* console and select `cluster1` and wait until the cluster creation is complete.
+
image::_images/Install/07_OCPV_Ready.png[]
+
The cluster can be `Ready` but the worker nodes may still be provisioning - which also means that *Cluster Operators* are still rolling out.
+
Wait until the `Cluster node pools` section switches from `Pending` to `Ready`

. Review the *Details* information of the cluster
+
image::_images/Install/08_OCPV_Guest_Details.png[]

. Click `Reval credentials` and copy the password for the `kubeadmin` user

. Click on the `Console URL` and accept the self-signed certificate

. Login to the new cluster with the credentials
+
image::_images/Install/09_OCPV_Guest_Home.png[]
+
Notice the `Infrastructure provider` is `KubeVirt`.

. Navigate in the left menu to *Compute* -> *Nodes* and review the workers
+
image::_images/Install/10_OCPV_Guest_Nodes.png[]

. Navigate to the left menu to *Storage* -> *StorageClasses* 
+
image::_images/Install/11_OCPV_Guest_StorageClass.png[]
+
Storage Class is a _interface_ to the host OpenShift Cluster storage class. Storage will be covered with more detail later on.

== Review the cluster using the CLI

It is possible download the `kubeconfig` using the UI interface and using the command `hcp.`

. Generate the kubeconfig for the `cluster1` cluster
+
[source,bash,role=execute]
----
hcp create kubeconfig --name cluster1 > cluster1-kubeconfig
----
+
.Sample Output
+
[%nowrap]
----
NAME       VERSION   KUBECONFIG                  PROGRESS   AVAILABLE   PROGRESSING   MESSAGE
cluster1             cluster1-admin-kubeconfig   Partial    False       False         Waiting for Kube APIServer deployment to become available
----

. Check the cluster operators
+
[source,bash,role=execute]
----
oc get co --kubeconfig=cluster1-kubeconfig
----
+
.Sample Output
+
[%nowrap]
----
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
console                                    4.14.5    True        False         False      66m     
csi-snapshot-controller                    4.14.5    True        False         False      72m     
dns                                        4.14.5    True        False         False      67m     
image-registry                             4.14.5    True        False         False      67m     
ingress                                    4.14.5    True        False         False      66m     
insights                                   4.14.5    True        False         False      67m     
kube-apiserver                             4.14.5    True        False         False      72m     
kube-controller-manager                    4.14.5    True        False         False      72m     
kube-scheduler                             4.14.5    True        False         False      72m     
kube-storage-version-migrator              4.14.5    True        False         False      67m     
monitoring                                 4.14.5    True        False         False      65m     
network                                    4.14.5    True        False         False      66m     
node-tuning                                4.14.5    True        False         False      69m     
openshift-apiserver                        4.14.5    True        False         False      72m     
openshift-controller-manager               4.14.5    True        False         False      72m     
openshift-samples                          4.14.5    True        False         False      66m     
operator-lifecycle-manager                 4.14.5    True        False         False      72m     
operator-lifecycle-manager-catalog         4.14.5    True        False         False      72m     
operator-lifecycle-manager-packageserver   4.14.5    True        False         False      72m     
service-ca                                 4.14.5    True        False         False      67m     
storage                                    4.14.5    True        False         False      72m   
----


. Check the cluster nodes
+
[source,bash,role=execute]
----
oc get nodes --kubeconfig=cluster1-kubeconfig
----
+
.Sample Output
+
[%nowrap]
----
NAME                      AGE   STATUS         READY
cluster1-ee50e7fb-ctrdd   62m   Running        True
cluster1-ee50e7fb-dc59k   62m   Running        True
----
